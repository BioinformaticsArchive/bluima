Index: src/main/java/ubic/whitetext/BrainRegionPipes.java
===================================================================
--- src/main/java/ubic/whitetext/BrainRegionPipes.java	(revision 920)
+++ src/main/java/ubic/whitetext/BrainRegionPipes.java	(working copy)
@@ -32,7 +32,7 @@
  */
 public class BrainRegionPipes {
 
-    final private static int window = 2; // /StaticOption.getInt("Window");
+    final private static int window = 3;
 
     public static List<Pipe> getPipes() throws Exception {
 
@@ -41,6 +41,8 @@
         pipes.add(new Jcas2TokenSequence());
         pipes.add(new Target2LabelSequence());
 
+        pipes.add(new RegexMatches("dummyPipe", Pattern.compile(".*")));
+
         // more piiiiipes
         addAllGoodPipes(pipes);
 
@@ -55,32 +57,15 @@
     public static void addAllGoodPipes(List<Pipe> pipes) throws Exception {
 
         List<String> usedPipeNames = new LinkedList<String>();
-
-        // TODO add here or in lemma?
-        // / if (StaticOption.getBoolean("TextPipe"))
-        addTextPipe(usedPipeNames, pipes);
-
-        // ren/ addOriginalMarkupPipes();
         addAreaRegexPipes(usedPipeNames, pipes);
-        // this catches tracts, change?
-        // /if (StaticOption.getBoolean("SubstringRegexPipes"))
         addSubstringRegexPipes(usedPipeNames, pipes);
         addSpineRegexPipes(usedPipeNames, pipes);
 
-        // /if (StaticOption
-        // /
-        // .getBoolean("SmallLexicons_TextPressoPipes_BrainRegionLexicons_AbbreviationLexiconPipes_AreaLexicons"))
-        // {
         addSmallLexicons(usedPipeNames, pipes, ignoreCase);
-        addTextPressoPipes(usedPipeNames, pipes, ignoreCase);
-        addBrainRegionLexicons(usedPipeNames, pipes, ignoreCase);
-        // ren/ addPigeonLexicon(usedPipeNames, pipes, ignoreCase);
-        addAbbreviationLexiconPipes(usedPipeNames, pipes);
+        // addAbbreviationLexiconPipes(usedPipeNames, pipes);
         addAreaLexicons(usedPipeNames, pipes, ignoreCase);
 
         addLengthPipes(usedPipeNames, pipes);
-
-        // / if (StaticOption.getBoolean("HandMadeRegexPipes_MalletNEPipes")) {
         addHandMadeRegexPipes(usedPipeNames, pipes);
         addMalletNEPipes(usedPipeNames, pipes);
     }
@@ -142,9 +127,8 @@
     public static void addSubstringRegexPipes(List<String> usedPipeNames,
             List<Pipe> pipes) throws Exception {
         usedPipeNames.add("Substring regexes");
-        String[] substrings = { "cortic", "cerebel" }; // "thalamic" and nuclie
-                                                       // are probably in the
-                                                       // 1-grams
+        String[] substrings = { "cortic", "cerebel", "thalamic", "nuclei",
+                "nucleus" };
 
         for (String substring : substrings) {
             pipes.add(new RegexMatches(substring + "Regex", Pattern.compile(
@@ -179,43 +163,6 @@
                 + "stop.txt"), ignoreCase));
     }
 
-    public static void addTextPressoPipes(List<String> usedPipeNames,
-            List<Pipe> pipes, boolean ignoreCase) throws FileNotFoundException,
-            Exception {
-        usedPipeNames.add("TextPresso");
-        // TEXTPRESSO files, files are split by how many tokens
-        for (int i = 1; i < 8; i++) {
-            pipes.add(new TrieLexiconMembership("textPresso" + i, new File(
-                    LEXICON_HOME + "TextPresso-wordLength-" + i + ".txt"),
-                    ignoreCase));
-        }
-        pipes.add(new TrieLexiconMembership("textPressoAll", new File(
-                LEXICON_HOME + "TextPresso-all.txt"), ignoreCase));
-
-        pipes.addAll(NGramPipeFactory.getAllGramsPipes("textPressoAll",
-                new File(LEXICON_HOME + "TextPresso-all.txt"), ignoreCase));
-    }
-
-    public static void addBrainRegionLexicons(List<String> usedPipeNames,
-            List<Pipe> pipes, boolean ignoreCase) throws FileNotFoundException,
-            Exception {
-        usedPipeNames.add("BrainRegions");
-        // BRAINREGION Lexicons
-        pipes.add(new TrieLexiconMembership("NNHu", new File(LEXICON_HOME
-                + "NN2002Human.txt"), ignoreCase));
-        pipes.add(new TrieLexiconMembership("NNMouseRat", new File(LEXICON_HOME
-                + "NN2007RatMouse.txt"), ignoreCase));
-        pipes.add(new TrieLexiconMembership("Allen", new File(LEXICON_HOME
-                + "Allen.txt"), ignoreCase));
-        pipes.add(new TrieLexiconMembership("BAMS", new File(LEXICON_HOME
-                + "BAMS.txt"), ignoreCase));
-        pipes.add(new TrieLexiconMembership("AllRegions", new File(LEXICON_HOME
-                + "AllRegions.txt"), ignoreCase));
-
-        pipes.addAll(NGramPipeFactory.getAllGramsPipes("AllRegions", new File(
-                LEXICON_HOME + "AllRegions.txt"), ignoreCase));
-    }
-
     public static void addAreaLexicons(List<String> usedPipeNames,
             List<Pipe> pipes, boolean ignoreCase) throws FileNotFoundException {
         usedPipeNames.add("Areawords");
Index: src/main/java/ch/epfl/bbp/uima/ae/BrainRegionAnnotator.java
===================================================================
--- src/main/java/ch/epfl/bbp/uima/ae/BrainRegionAnnotator.java	(revision 920)
+++ src/main/java/ch/epfl/bbp/uima/ae/BrainRegionAnnotator.java	(working copy)
@@ -39,6 +39,7 @@
 import cc.mallet.fst.Experiment.Trail;
 import cc.mallet.fst.MyMultiSegmentationEvaluator;
 import cc.mallet.fst.Transducer;
+import cc.mallet.pipe.Pipe;
 import cc.mallet.pipe.SerialPipes;
 import cc.mallet.types.Instance;
 import cc.mallet.types.InstanceList;
@@ -69,7 +70,7 @@
     private static Logger LOG = LoggerFactory
             .getLogger(BrainRegionAnnotator.class);
 
-    static final boolean SILENT_MALLET_LOGGER = true;
+    static final boolean SILENT_MALLET_LOGGER = false;
     static final boolean PRINT_MISSCLASSIFIED = false;
 
     static enum Mode {
@@ -98,6 +99,11 @@
     private InstanceList trainingInstanceList; // for training and eval modes
     private CRF inferenceCrf = null; // only for inference mode
 
+    private CRFTrainerByThreadedLabelLikelihood trainer;
+    private CRF crfTrain;
+    private boolean crfConfigured = false;
+    private Pipe pipes;
+
     // overwrite Mallet default logs (tooo verbose)
     static {
         if (SILENT_MALLET_LOGGER) {
@@ -120,6 +126,9 @@
             throws ResourceInitializationException {
         super.initialize(context);
         try {
+
+            pipes = new SerialPipes(BrainRegionPipes.getPipes());
+
             LOG.debug("Running in {} mode", mode);
 
             if (mode.equals(infer)) {
@@ -134,9 +143,15 @@
             } else {
                 // create empty instanceList, init pipes
                 trainingInstanceList = new InstanceList(//
-                        new SerialPipes(BrainRegionPipes.getPipes()));
-                if (mode.equals(train))
+                        pipes);
+                if (mode.equals(train)) {
+
                     checkNotNull(modelFile, "missing model output file");
+                    crfTrain = new CRF(trainingInstanceList.getPipe(), null);
+                    // configure(crfTrain, trainingInstanceList);
+                    trainer = new CRFTrainerByThreadedLabelLikelihood(crfTrain,
+                            threads);
+                }
             }
 
         } catch (Exception e) {
@@ -144,6 +159,8 @@
         }
     }
 
+    int t = 2;
+
     public void process(JCas jCas) throws AnalysisEngineProcessException {
         int pmId = BlueCasUtil.getHeaderIntDocId(jCas);
 
@@ -170,7 +187,7 @@
                     @SuppressWarnings({ "unchecked", "rawtypes" })
                     Sequence<String> labels = inferenceCrf
                             .transduce((Sequence) instanceToInfer.getData());
-                    
+
                     // post-aggregate I-labels of Tokens into BrainRegions
                     Integer begin = null, end = null; // 2-state FSA: O/I
                     List<Token> tokens = selectCovered(Token.class, s);
@@ -198,10 +215,30 @@
             } catch (Exception e) {
                 LOG.warn("could not perform inference on sentence " + pmId, e);
             }
-           
+
         } else { // train or eval
+
             Instance instance = new Instance(jCas, null, pmId, jCas);
             trainingInstanceList.addThruPipe(instance);
+            if (t % 10000 == 0) {
+                LOG.info("incrementally training, t={}", t);
+                if (!crfConfigured) {
+                    crfTrain.addStatesForLabelsConnectedAsIn(trainingInstanceList);
+                    crfConfigured = true;
+                }
+                if (t % 500000 == 0) {
+                    trainer.train(trainingInstanceList);
+                    // write crf
+                    crfTrain.write(new File("target/" + t + ".model"));
+
+                } else {
+                    trainer.train(trainingInstanceList, 1);
+                }
+
+                // reset
+                trainingInstanceList = new InstanceList(pipes);
+            }
+            t++;
         }
     }
 
@@ -212,42 +249,45 @@
 
         try {
 
-            if (mode.equals(eval)) { // cross validate
-                Experiment experiment = new Experiment();
-                final int folds = 8;
-                LOG.info("starting {} trials of {}-fold cross validation",
-                        trials, folds);
-                for (int t = 0; t < trials; t++) {
-                    Trail trail = new Trail();
-                    cc.mallet.types.InstanceList.CrossValidationIterator crossValidationIt = trainingInstanceList
-                            .crossValidationIterator(folds,
-                                    new Random().nextInt());
-                    int f = 0;
-                    while (crossValidationIt.hasNext()) {
-                        LOG.info(">>>> Trial {} Fold {} >>>>>>>>>>>>", t, f);
-                        InstanceList[] il = crossValidationIt.nextSplit();
-                        CRF crf = new CRF(trainingInstanceList.getPipe(), null);
-                        configure(crf, trainingInstanceList);
-                        trail.add(evaluate(f++, crf, il[0], il[1], threads));
-                    }
-                    experiment.add(trail);
+            // if (mode.equals(eval)) { // cross validate
+            // Experiment experiment = new Experiment();
+            // final int folds = 8;
+            // LOG.info("starting {} trials of {}-fold cross validation",
+            // trials, folds);
+            // for (int t = 0; t < trials; t++) {
+            // Trail trail = new Trail();
+            // cc.mallet.types.InstanceList.CrossValidationIterator
+            // crossValidationIt = trainingInstanceList
+            // .crossValidationIterator(folds,
+            // new Random().nextInt());
+            // int f = 0;
+            // while (crossValidationIt.hasNext()) {
+            // LOG.info(">>>> Trial {} Fold {} >>>>>>>>>>>>", t, f);
+            // InstanceList[] il = crossValidationIt.nextSplit();
+            // CRF crf = new CRF(trainingInstanceList.getPipe(), null);
+            // configure(crf, trainingInstanceList);
+            // trail.add(evaluate(f++, crf, il[0], il[1], threads));
+            // }
+            // experiment.add(trail);
+            // }
+            // LOG.error("RRReport ", experiment.getReport());
+            // // /
+            // LOG.error("Done here, forcing exit");
+            // // /
+            // System.exit(0);
+            // } else
+            if (mode.equals(train)) {
+                // train model
+
+                if (!crfConfigured) {
+                    crfTrain.addStatesForLabelsConnectedAsIn(trainingInstanceList);
+                    crfConfigured = true;
                 }
-                LOG.error("RRReport ", experiment.getReport());
-                // /
-                LOG.error("Done here, forcing exit");
-                // /
-                System.exit(0);
+                trainer.train(trainingInstanceList);
 
-            } else if (mode.equals(train)) {
-                // train model
-                CRF crf = new CRF(trainingInstanceList.getPipe(), null);
-                configure(crf, trainingInstanceList);
-                CRFTrainerByThreadedLabelLikelihood trainer = new CRFTrainerByThreadedLabelLikelihood(
-                        crf, threads);
-                trainer.train(trainingInstanceList);
                 LOG.info("done training CRF");
                 // write model
-                crf.write(new File(modelFile));
+                crfTrain.write(new File(modelFile));
             }
 
         } catch (Exception e) {
@@ -256,29 +296,31 @@
         }
     }
 
-    private static void configure(CRF _crf, InstanceList trainingSet) {
+    // private static void configure(CRF _crf, InstanceList trainingSet) {
+    //
+    // _crf.addStatesForLabelsConnectedAsIn(trainingSet);
+    // //
+    // _crf.addFullyConnectedStatesForTriLabels()StatesForLabelsConnectedAsIn(trainingSet);
+    // // CRFTrainerByLabelLikelihood trainer = new
+    // // CRFTrainerByLabelLikelihood(
+    // // crf);
+    // // trainer.setGaussianPriorVariance(1d);
+    //
+    // int[] orders = new int[] { 1 };
+    // Pattern forbiddenPat = Pattern.compile("\\s");
+    // Pattern allowedPat = Pattern.compile(".*");
+    //
+    // String outside = Jcas2TokenSequence.TARGET_O;
+    // String startName = _crf.addOrderNStates(trainingSet, orders, null,
+    // outside, null, null, true);
+    // // String startName = crf.addOrderNStates(trainingSet, orders, null,
+    // // null, null, null, true);
+    //
+    // // for (int i = 0; i < _crf.numStates(); i++)
+    // // _crf.getState(i).setInitialWeight(Transducer.IMPOSSIBLE_WEIGHT);
+    // // _crf.getState(startName).setInitialWeight(0.0);
+    // }
 
-        // crf.addStatesForLabelsConnectedAsIn(trainingSet);
-        // CRFTrainerByLabelLikelihood trainer = new
-        // CRFTrainerByLabelLikelihood(
-        // crf);
-        // trainer.setGaussianPriorVariance(1d);
-
-        int[] orders = new int[] { 1 };
-        Pattern forbiddenPat = Pattern.compile("\\s");
-        Pattern allowedPat = Pattern.compile(".*");
-
-        String outside = Jcas2TokenSequence.TARGET_O;
-        String startName = _crf.addOrderNStates(trainingSet, orders, null,
-                outside, forbiddenPat, allowedPat, true);
-        // String startName = crf.addOrderNStates(trainingSet, orders, null,
-        // null, null, null, true);
-
-        for (int i = 0; i < _crf.numStates(); i++)
-            _crf.getState(i).setInitialWeight(Transducer.IMPOSSIBLE_WEIGHT);
-        _crf.getState(startName).setInitialWeight(0.0);
-    }
-
     // private static void evaluate_old(int iterationId, CRF crf,
     // InstanceList trainingSet, InstanceList testingSet) {
     //
@@ -295,56 +337,57 @@
     // evaluator.getAccuracy("ttt"));
     // }
 
-    /** MultiSegmentationEvaluator */
-    private static Fold evaluate(int iterationId, CRF crf,
-            InstanceList trainingSet, InstanceList testingSet, int threads) {
-
-        // TODO 1 see if it works (better) with simpler setup
-
-        CRFTrainerByThreadedLabelLikelihood trainer = new CRFTrainerByThreadedLabelLikelihood(
-                crf, threads);
-        // CRFTrainerByLabelLikelihood trainer = new
-        // CRFTrainerByLabelLikelihood(crf);
-        trainer.setGaussianPriorVariance(1);
-
-        String[] tags = new String[] { Jcas2TokenSequence.TARGET_I };
-        String[] continueTags = tags;
-
-        MyMultiSegmentationEvaluator eval = new MyMultiSegmentationEvaluator(
-                new InstanceList[] { testingSet },//
-                new String[] { "TTesting" }, tags, continueTags,
-                PRINT_MISSCLASSIFIED);
-        // trainer.addEvaluator(eval);
-        trainer.train(trainingSet);
-        eval.evaluate(trainer); // eval at end of training
-        LOG.info("FOLD {} --> " + eval.getReport(), iterationId);
-        return new Fold(eval);
-
-        // TODO trainer.trainWithFeatureInduction
-
-        // TODO
-        // if ( runner.isInduceFeatures() ) {
-        // // Number of maximizer iterations between each call to the Feature
-        // Inducer. (10 in simpletagger and TUI)
-        // int numIterationsBetweenFeatureInductions = 10;
-        //
-        // // Maximum number of rounds of feature induction. (20 in
-        // simpleTagger, 99 in TUI)
-        // int numFeatureInductions = 20;
-        //
-        // // Maximum number of features to induce at each round of induction.
-        // (500 in simpletagger, 200 in TUI)
-        // int numFeaturesPerFeatureInduction = 300;
-        // // splits = new double[] {.1, .2, .5, .7}
-        //
-        // crft.trainWithFeatureInduction( training, null, testing, eval,
-        // iterations,
-        // numIterationsBetweenFeatureInductions, numFeatureInductions,
-        // numFeaturesPerFeatureInduction, 0.5,
-        // false, null );
-        // } else {
-        // // before
-        // converged = crft.train( training ); // , iterations );
-        // }
-    }
+    // /** MultiSegmentationEvaluator */
+    // private static Fold evaluate(int iterationId, CRF crf,
+    // InstanceList trainingSet, InstanceList testingSet, int threads) {
+    //
+    // // TODO 1 see if it works (better) with simpler setup
+    //
+    // CRFTrainerByThreadedLabelLikelihood trainer = new
+    // CRFTrainerByThreadedLabelLikelihood(
+    // crf, threads);
+    // // CRFTrainerByLabelLikelihood trainer = new
+    // // CRFTrainerByLabelLikelihood(crf);
+    // trainer.setGaussianPriorVariance(1);
+    //
+    // String[] tags = new String[] { Jcas2TokenSequence.TARGET_I };
+    // String[] continueTags = tags;
+    //
+    // MyMultiSegmentationEvaluator eval = new MyMultiSegmentationEvaluator(
+    // new InstanceList[] { testingSet },//
+    // new String[] { "TTesting" }, tags, continueTags,
+    // PRINT_MISSCLASSIFIED);
+    // // trainer.addEvaluator(eval);
+    // trainer.train(trainingSet);
+    // eval.evaluate(trainer); // eval at end of training
+    // LOG.info("FOLD {} --> " + eval.getReport(), iterationId);
+    // return new Fold(eval);
+    //
+    // // TODO trainer.trainWithFeatureInduction
+    //
+    // // TODO
+    // // if ( runner.isInduceFeatures() ) {
+    // // // Number of maximizer iterations between each call to the Feature
+    // // Inducer. (10 in simpletagger and TUI)
+    // // int numIterationsBetweenFeatureInductions = 10;
+    // //
+    // // // Maximum number of rounds of feature induction. (20 in
+    // // simpleTagger, 99 in TUI)
+    // // int numFeatureInductions = 20;
+    // //
+    // // // Maximum number of features to induce at each round of induction.
+    // // (500 in simpletagger, 200 in TUI)
+    // // int numFeaturesPerFeatureInduction = 300;
+    // // // splits = new double[] {.1, .2, .5, .7}
+    // //
+    // // crft.trainWithFeatureInduction( training, null, testing, eval,
+    // // iterations,
+    // // numIterationsBetweenFeatureInductions, numFeatureInductions,
+    // // numFeaturesPerFeatureInduction, 0.5,
+    // // false, null );
+    // // } else {
+    // // // before
+    // // converged = crft.train( training ); // , iterations );
+    // // }
+    // }
 }
Index: src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence.java
===================================================================
--- src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence.java	(revision 920)
+++ src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence.java	(working copy)
@@ -14,16 +14,12 @@
 
 import org.apache.uima.cas.text.AnnotationFS;
 import org.apache.uima.jcas.JCas;
-import org.apache.uima.jcas.cas.DoubleArray;
 
 import cc.mallet.pipe.Pipe;
 import cc.mallet.types.Instance;
 import cc.mallet.types.TokenSequence;
-import ch.epfl.bbp.uima.topicmodels.annotators.DCATopicModelsAnnotator;
 import ch.epfl.bbp.uima.types.BrainRegion;
-import ch.epfl.bbp.uima.types.LinnaeusSpecies;
-import ch.epfl.bbp.uima.types.Topic;
-import ch.epfl.bbp.uima.utils.StaticOption;
+import ch.epfl.bbp.uima.types.BrainRegionDictTerm;
 import de.julielab.jules.types.Sentence;
 import de.julielab.jules.types.Token;
 
@@ -38,10 +34,7 @@
     private static final long serialVersionUID = 1L;
 
     public static final String PROPERTY_POS = "u_POS_";
-    public static final String PROPERTY_LEMMA = "u_LEMMA_";
-    public static final String PROPERTY_TEXT = "u_TEXT_";
-    public static final String PROPERTY_TOPICS = "u_TOPICID_";
-    public static final String PROPERTY_SPECIES = "u_SPECIES_";
+    public static final String PROPERTY_VERB_LEMMA = "u_V_LEM_";
 
     public static final String TARGET_I = "I";
     public static final String TARGET_O = "O";
@@ -78,18 +71,8 @@
             final Map<AnnotationFS, Collection<AnnotationFS>> coveringBrainRegions = indexCovering(
                     jCas.getCas(), //
                     getType(jCas, Token.class),
-                    getType(jCas, BrainRegion.class));
+                    getType(jCas, BrainRegionDictTerm.class));
 
-            // topics from DCA. not all tokens have topics (e.g. tokens
-            // representing stopwords, or hapax)
-            // key: each token; value: a list of Topics covering that token
-            final Map<AnnotationFS, Collection<AnnotationFS>> coveringTopics = indexCovering(
-                    jCas.getCas(), //
-                    getType(jCas, Token.class), getType(jCas, Topic.class));
-
-            final Collection<LinnaeusSpecies> species = select(jCas,
-                    LinnaeusSpecies.class);
-
             int i = 0;
             for (Sentence s : select(jCas, Sentence.class)) {
 
@@ -104,81 +87,11 @@
 
                     // POS, LEMMA
                     malletToken.setFeatureValue(PROPERTY_POS + t.getPos(), 1.0);
-                    // /if (GridSearchConfiguration.getBoolean("Lemma")) {
-                    if (t.getLemmaStr() != null && t.getLemmaStr().length() > 1)
-                        malletToken.setFeatureValue(
-                                PROPERTY_LEMMA + t.getLemmaStr(), 1.0);
-                    // else
-                    // malletToken.setFeatureValue(
-                    // PROPERTY_TEXT + t.getCoveredText(), 1.0);
+//                    if (t.getPos() != null && t.getPos().startsWith("V")) {
+//                        malletToken.setFeatureValue(
+//                                PROPERTY_VERB_LEMMA + t.getLemmaStr(), 1.0);
+//                    }
 
-                    // TOPICS
-                    if (coveringTopics.containsKey(t)) {
-                        Topic top = (Topic) coveringTopics.get(t).iterator()
-                                .next();
-
-                        if ("a".equals("a")) {
-                            malletToken.setFeatureValue(PROPERTY_TOPICS//
-                                    + top.getMostLikelyTopic(), 1.0);
-
-                        } else {
-                            int topicScenario = StaticOption
-                                    .getInt("topScenario");
-
-                            if (topicScenario == 1) { // top1
-                                malletToken.setFeatureValue(PROPERTY_TOPICS//
-                                        + top.getMostLikelyTopic(), 1.0);
-
-                            } else if (topicScenario == 2) { // staged
-
-                                // format: u_TOPICID_{topicId}_{category}
-                                DoubleArray scores = top.getScores();
-                                for (int topic_id = 0; topic_id < scores.size(); topic_id++) {
-                                    double score = scores.get(topic_id);
-                                    // System.out.println(topic_id+"\t"+score);
-                                    if (score >= 0.01d && score < 0.05d) {
-                                        malletToken.setFeatureValue(
-                                                PROPERTY_TOPICS + topic_id
-                                                        + "_1", 1.0);
-                                    } else if (score >= 0.05d && score < 0.1d) {
-                                        malletToken.setFeatureValue(
-                                                PROPERTY_TOPICS + topic_id
-                                                        + "_2", 1.0);
-                                    } else if (score >= 0.1d && score < 0.2d) {
-                                        malletToken.setFeatureValue(
-                                                PROPERTY_TOPICS + topic_id
-                                                        + "_3", 1.0);
-                                    } else if (score >= 0.2d) {
-                                        malletToken.setFeatureValue(
-                                                PROPERTY_TOPICS + topic_id
-                                                        + "_4", 1.0);
-                                    }
-                                }
-
-                            } else { // topN & minProb
-
-                                int topNTopics = StaticOption
-                                        .getInt("topNTopics");
-                                double minProb = StaticOption
-                                        .getDouble("minProb");
-                                for (int topTopic : DCATopicModelsAnnotator
-                                        .topNTopics(top.getScores(),
-                                                topNTopics, minProb)) {
-                                    malletToken.setFeatureValue(PROPERTY_TOPICS
-                                            + topTopic, 1.0);
-                                }
-                            }
-                        }
-                    }
-
-                    // SPECIES
-                    if (species != null && !species.isEmpty()) {
-                        for (LinnaeusSpecies specie : species) {
-                            malletToken.setFeatureValue(PROPERTY_SPECIES
-                                    + specie.getMostProbableSpeciesId(), 1.0);
-                        }
-                    }
-
                     // TARGET annots for brain regions
                     if (coveringBrainRegions.containsKey(t)) {
                         target.add(TARGET_I);
@@ -188,8 +101,7 @@
                 }
 
                 output.add(new Instance(new TokenSequence(data), target, pmId
-                        + "__" + i, s));
-                // TODO s(entence) "unlinked" in the end, need to serialize
+                        + "__" + i, null));
                 i++;
             }
         }
Index: src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence2.java
===================================================================
--- src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence2.java	(revision 0)
+++ src/main/java/ch/epfl/bbp/uima/ae/Jcas2TokenSequence2.java	(revision 0)
@@ -0,0 +1,160 @@
+package ch.epfl.bbp.uima.ae;
+
+import static com.google.common.collect.Lists.newArrayList;
+import static com.google.common.collect.Sets.newHashSet;
+import static org.uimafit.util.CasUtil.indexCovering;
+import static org.uimafit.util.JCasUtil.getType;
+import static org.uimafit.util.JCasUtil.select;
+import static org.uimafit.util.JCasUtil.selectCovered;
+
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.uima.cas.text.AnnotationFS;
+import org.apache.uima.jcas.JCas;
+import org.apache.uima.jcas.tcas.Annotation;
+
+import cc.mallet.pipe.Pipe;
+import cc.mallet.types.Instance;
+import cc.mallet.types.TokenSequence;
+import ch.epfl.bbp.uima.types.BrainRegion;
+import ch.epfl.bbp.uima.types.LinnaeusSpecies;
+import ch.epfl.bbp.uima.types.ShortestPath;
+import de.julielab.jules.types.DocumentAnnotation;
+import de.julielab.jules.types.Header;
+import de.julielab.jules.types.Sentence;
+import de.julielab.jules.types.Token;
+
+/**
+ * Creates a {@link cc.mallet.types.TokenSequence} from a {@link JCas}, reusing
+ * the UIMA {@link Sentence} and {@link Token}. Sets the (true) label based on
+ * the presence of a {@link BrainRegion} covering the {@link Token}.
+ * 
+ * @author renaud.richardet@epfl.ch
+ */
+public class Jcas2TokenSequence2 extends Pipe {
+    private static final long serialVersionUID = 1L;
+
+    public static final String PROPERTY_POS = "u_POS_";
+    public static final String PROPERTY_LEMMA = "u_LEMMA_";
+    public static final String PROPERTY_TEXT = "u_TEXT_";
+    public static final String PROPERTY_TOPICS = "u_TOPICID_";
+    public static final String PROPERTY_SPECIES = "u_SPECIES_";
+
+    public static final String TARGET_I = "I";
+    public static final String TARGET_O = "O";
+
+    final static Set<String> skip = newHashSet(
+            DocumentAnnotation.class.getName(),
+            org.apache.uima.jcas.tcas.DocumentAnnotation.class.getName(),
+            Header.class.getName(), //
+            Sentence.class.getName(), //
+            ShortestPath.class.getName(), //
+            BrainRegion.class.getName());// FIXME
+
+    /**
+     * IN: one {@link JCas} <br/>
+     * data : 1 {@link JCas}<br>
+     * targ : none<br>
+     * name : pmId<br>
+     * srce : {@link JCas}<br>
+     * <br>
+     * OUT: {@link Instance}s, each corresponding to a {@link Sentence}<br/>
+     * data : a {@link TokenSequence}, one {@link cc.mallet.types.Token} per
+     * UIMA {@link Token}<br>
+     * targ : labels for training (if any), based on covering UIMA
+     * {@link BrainRegion} annotations<br>
+     * name : pmId<br>
+     * srce : {@link Sentence}<br>
+     * <br>
+     * Note: this {@link Pipe} creates more {@link Instance} than it gets (one
+     * output {@link Instance} per input {@link Sentence}).
+     */
+    @Override
+    public Iterator<Instance> newIteratorFrom(Iterator<Instance> source) {
+        List<Instance> output = new LinkedList<Instance>();
+
+        while (source.hasNext()) {
+            Instance carrier = (Instance) source.next();
+            JCas jCas = (JCas) carrier.getData();
+            int pmId = (Integer) carrier.getName();
+
+            // gold labels from training corpus
+            // key: each token; value: a list of BR covering that token
+            final Map<AnnotationFS, Collection<AnnotationFS>> coveringBrainRegions = indexCovering(
+                    jCas.getCas(), //
+                    getType(jCas, Token.class),
+                    getType(jCas, BrainRegion.class));
+
+            final Map<AnnotationFS, Collection<AnnotationFS>> coveringAnnots = indexCovering(
+                    jCas.getCas(), //
+                    getType(jCas, Token.class), getType(jCas, Annotation.class));
+
+            final Collection<LinnaeusSpecies> species = select(jCas,
+                    LinnaeusSpecies.class);
+
+            int i = 0;
+            for (Sentence s : select(jCas, Sentence.class)) {
+
+                List<cc.mallet.types.Token> data = newArrayList();
+                TokenSequence target = new TokenSequence();
+
+                for (Token t : selectCovered(Token.class, s)) {
+
+                    cc.mallet.types.Token malletToken = new cc.mallet.types.Token(
+                            t.getCoveredText());
+                    data.add(malletToken);
+
+                    // POS, LEMMA
+                    malletToken.setFeatureValue(PROPERTY_POS + t.getPos(), 1.0);
+                    // /if (GridSearchConfiguration.getBoolean("Lemma")) {
+                    if (t.getLemmaStr() != null && t.getLemmaStr().length() > 1)
+                        malletToken.setFeatureValue(
+                                PROPERTY_LEMMA + t.getLemmaStr(), 1.0);
+                    // else
+                    // malletToken.setFeatureValue(
+                    // PROPERTY_TEXT + t.getCoveredText(), 1.0);
+
+                    // TOPICS
+                    if (coveringAnnots.containsKey(t)) {
+                        Iterator<AnnotationFS> coveringIt = coveringAnnots.get(
+                                t).iterator();
+                        while (coveringIt.hasNext()) {
+                            AnnotationFS a = coveringIt.next();
+                            // filter
+                            String aName = a.getClass().getName();
+                            if (!skip.contains(aName) //
+                                    && a.getClass() != Token.class // do not
+                                                                   // remove
+                                                                   // Tokens
+                                    && a.getEnd() != 0) { // do not remove annot
+                                                          // without
+                                                          // text
+                                malletToken.setFeatureValue(PROPERTY_TOPICS
+                                        + aName, 1.0);
+                            }
+                        }
+
+                    }
+
+                    // TARGET annots for brain regions
+                    if (coveringBrainRegions.containsKey(t)) {
+                        target.add(TARGET_I);
+                    } else {
+                        target.add(TARGET_O);
+                    }
+                }
+
+                output.add(new Instance(new TokenSequence(data), target, pmId
+                        + "__" + i, s));
+                // TODO s(entence) "unlinked" in the end, need to serialize
+                i++;
+            }
+        }
+        return output.iterator();
+    }
+}
