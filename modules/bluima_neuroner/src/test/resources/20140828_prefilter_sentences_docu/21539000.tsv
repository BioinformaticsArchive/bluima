21539000	A kernel partial least squares method was used to select the best descriptors and the selected descriptors were used as input neurons in neural network model. These tight junctions are composed of membrane-associated accessory proteins, such as occludin and claudin, and intracellular proteins.[4,5] This barrier is formed by the endothelial cells of the cerebral capillaries, which essentially comprise the major exchange interface between the blood and the brain. Different mechanisms, such as passive transcellular diffusion, paracellular diffusion, and active transport, have been proposed for uptake across this barrier,[6 – 8] with the tight endothelium of brain capillaries constituting the principal permeability barrier for the passive transport of substances across the barrier. polar surface area is a commonly used medicinal chemistry metric for the optimization of cell permeability. Molecules with a polar surface area of greater than 140 angstroms squared are usually believed to be poor at permeating cell membranes. Also biopartitioning micellar chromatography has been used in modelling many biopartitioning processes, including human drug absorption,[20] blood – brain barrier penetration,[21] ocular tissue permeability,[22] skin permeability,[23] etc. Those which are reported to transport across cell membrane with the participation of some transport protein and which have molecular weight less than 200 and are hydrophilic at the physiological conditions, were excluded from the drug set in advance, for example, verapamil, quinidine, doxorubicin, vinblastine, risperidone and salicylic acid, caffeine, theophylline, acetaminophen. The network architecture consisted of seven neurons in the input layer corresponding to the seven mentioned descriptors. The output layer had one neuron that predicts the polar surface area. The number of neurons in the hidden layer is unknown and needs to be optimized. In addition to the number of neurons in the hidden layer, the learning rate, the momentum and the number of iterations also should be optimized. In this work, the number of neurons in the hidden layer and other parameters except the number of iterations were simultaneously optimized. A MATLAB program was written to change the number of neurons in the hidden layer from two to seven, the learning rate from 0.001 to 0.1 with a step of 0.001 and the momentum from 0.1 to 0.99 with a step of 0.01. It was realized that the root mean square error for the training set was minimum when two neurons were selected in the hidden layer and the learning rate and the momentum values were 0.4 and 0.3, respectively. Three models have good predictive capacity and excellent statistical parameters.